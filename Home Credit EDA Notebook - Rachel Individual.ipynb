{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b945433e",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Title:-Group-2-Home-Credit-Exploratory-Data-Analysis\" data-toc-modified-id=\"Title:-Group-2-Home-Credit-Exploratory-Data-Analysis-1\">Title: Group 2 Home Credit Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#By-Rachel-Butterfield-7/22/23\" data-toc-modified-id=\"By-Rachel-Butterfield-7/22/23-1.0.1\">By Rachel Butterfield 7/22/23</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importing-Necessary-Packages\" data-toc-modified-id=\"Importing-Necessary-Packages-1.0.1.1\">Importing Necessary Packages</a></span></li><li><span><a href=\"#Making-the-dataframes-for-each-of-our-CSV-files\" data-toc-modified-id=\"Making-the-dataframes-for-each-of-our-CSV-files-1.0.1.2\">Making the dataframes for each of our CSV files</a></span></li><li><span><a href=\"#Getting-the-unique-values-for-the-categorical-columns-in-the-dataframe\" data-toc-modified-id=\"Getting-the-unique-values-for-the-categorical-columns-in-the-dataframe-1.0.1.3\">Getting the unique values for the categorical columns in the dataframe</a></span></li><li><span><a href=\"#Evaluating-the-missing-data-from-the-dataframes\" data-toc-modified-id=\"Evaluating-the-missing-data-from-the-dataframes-1.0.1.4\">Evaluating the missing data from the dataframes</a></span></li><li><span><a href=\"#Filtering-missing-values-and-printing-summary-metrics\" data-toc-modified-id=\"Filtering-missing-values-and-printing-summary-metrics-1.0.1.5\">Filtering missing values and printing summary metrics</a></span></li><li><span><a href=\"#Participation\" data-toc-modified-id=\"Participation-1.0.1.6\">Participation</a></span></li><li><span><a href=\"#Rachel-Butterfield\" data-toc-modified-id=\"Rachel-Butterfield-1.0.1.7\">Rachel Butterfield</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4796c196",
   "metadata": {},
   "source": [
    "# Title: Group 2 Home Credit Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c64acb",
   "metadata": {},
   "source": [
    "### By Rachel Butterfield 7/22/23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8df608",
   "metadata": {},
   "source": [
    "This notebook contains the EDA coding portion I completed individually as part of our MSBA Capstone Project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbccabc",
   "metadata": {},
   "source": [
    "#### Importing Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f26ae493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362a6437",
   "metadata": {},
   "source": [
    "#### Making the dataframes for each of our CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ffa8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Dataframes of each of the CSV Files\n",
    "\n",
    "applicationtestDF = pd.read_csv(\"application_test.csv\")\n",
    "applicationtrainDF = pd.read_csv(\"application_train.csv\")\n",
    "bureauDF = pd.read_csv(\"bureau.csv\")\n",
    "bureaubalanceDF = pd.read_csv(\"bureau_balance.csv\")\n",
    "creditcardbalanceDF = pd.read_csv(\"credit_card_balance.csv\")\n",
    "installmentpaymentsDF = pd.read_csv(\"installments_payments.csv\")\n",
    "poscashDF = pd.read_csv(\"POS_CASH_balance.csv\")\n",
    "previousDF = pd.read_csv(\"previous_application.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab3010",
   "metadata": {},
   "source": [
    "#### Getting the unique values for the categorical columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "701b76ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 122)\n",
      "(48744, 121)\n"
     ]
    }
   ],
   "source": [
    "#Shape of the train and test set\n",
    "\n",
    "#training set\n",
    "num_rows_train = applicationtrainDF.shape\n",
    "print(num_rows_train)\n",
    "\n",
    "#test set\n",
    "num_rows_test = applicationtestDF.shape\n",
    "print(num_rows_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09c058",
   "metadata": {},
   "source": [
    "There are 50 variables in both data sets where 40% or more of their values are null. Nearly all of those variables involve a applicant's information about their living accomodations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13435cb5",
   "metadata": {},
   "source": [
    "#### Evaluating the missing data from the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e7ee6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Missing Count  Percentage\n",
      "COMMONAREA_MEDI                      214865       69.87\n",
      "COMMONAREA_AVG                       214865       69.87\n",
      "COMMONAREA_MODE                      214865       69.87\n",
      "NONLIVINGAPARTMENTS_MEDI             213514       69.43\n",
      "NONLIVINGAPARTMENTS_MODE             213514       69.43\n",
      "NONLIVINGAPARTMENTS_AVG              213514       69.43\n",
      "FONDKAPREMONT_MODE                   210295       68.39\n",
      "LIVINGAPARTMENTS_MODE                210199       68.35\n",
      "LIVINGAPARTMENTS_MEDI                210199       68.35\n",
      "LIVINGAPARTMENTS_AVG                 210199       68.35\n",
      "FLOORSMIN_MODE                       208642       67.85\n",
      "FLOORSMIN_MEDI                       208642       67.85\n",
      "FLOORSMIN_AVG                        208642       67.85\n",
      "YEARS_BUILD_MODE                     204488       66.50\n",
      "YEARS_BUILD_MEDI                     204488       66.50\n",
      "YEARS_BUILD_AVG                      204488       66.50\n",
      "OWN_CAR_AGE                          202929       65.99\n",
      "LANDAREA_AVG                         182590       59.38\n",
      "LANDAREA_MEDI                        182590       59.38\n",
      "LANDAREA_MODE                        182590       59.38\n",
      "BASEMENTAREA_MEDI                    179943       58.52\n",
      "BASEMENTAREA_AVG                     179943       58.52\n",
      "BASEMENTAREA_MODE                    179943       58.52\n",
      "EXT_SOURCE_1                         173378       56.38\n",
      "NONLIVINGAREA_MEDI                   169682       55.18\n",
      "NONLIVINGAREA_MODE                   169682       55.18\n",
      "NONLIVINGAREA_AVG                    169682       55.18\n",
      "ELEVATORS_MEDI                       163891       53.30\n",
      "ELEVATORS_MODE                       163891       53.30\n",
      "ELEVATORS_AVG                        163891       53.30\n",
      "WALLSMATERIAL_MODE                   156341       50.84\n",
      "APARTMENTS_MODE                      156061       50.75\n",
      "APARTMENTS_MEDI                      156061       50.75\n",
      "APARTMENTS_AVG                       156061       50.75\n",
      "ENTRANCES_MODE                       154828       50.35\n",
      "ENTRANCES_AVG                        154828       50.35\n",
      "ENTRANCES_MEDI                       154828       50.35\n",
      "LIVINGAREA_MEDI                      154350       50.19\n",
      "LIVINGAREA_MODE                      154350       50.19\n",
      "LIVINGAREA_AVG                       154350       50.19\n",
      "HOUSETYPE_MODE                       154297       50.18\n",
      "FLOORSMAX_MEDI                       153020       49.76\n",
      "FLOORSMAX_AVG                        153020       49.76\n",
      "FLOORSMAX_MODE                       153020       49.76\n",
      "YEARS_BEGINEXPLUATATION_AVG          150007       48.78\n",
      "YEARS_BEGINEXPLUATATION_MEDI         150007       48.78\n",
      "YEARS_BEGINEXPLUATATION_MODE         150007       48.78\n",
      "TOTALAREA_MODE                       148431       48.27\n",
      "EMERGENCYSTATE_MODE                  145755       47.40\n",
      "OCCUPATION_TYPE                       96391       31.35\n",
      "EXT_SOURCE_3                          60965       19.83\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK            41519       13.50\n",
      "AMT_REQ_CREDIT_BUREAU_DAY             41519       13.50\n",
      "AMT_REQ_CREDIT_BUREAU_MON             41519       13.50\n",
      "AMT_REQ_CREDIT_BUREAU_QRT             41519       13.50\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR            41519       13.50\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR            41519       13.50\n",
      "NAME_TYPE_SUITE                        1292        0.42\n",
      "DEF_30_CNT_SOCIAL_CIRCLE               1021        0.33\n",
      "OBS_60_CNT_SOCIAL_CIRCLE               1021        0.33\n",
      "DEF_60_CNT_SOCIAL_CIRCLE               1021        0.33\n",
      "OBS_30_CNT_SOCIAL_CIRCLE               1021        0.33\n",
      "EXT_SOURCE_2                            660        0.21\n",
      "AMT_GOODS_PRICE                         278        0.09\n",
      "AMT_ANNUITY                              12        0.00\n",
      "CNT_FAM_MEMBERS                           2        0.00\n",
      "DAYS_LAST_PHONE_CHANGE                    1        0.00\n"
     ]
    }
   ],
   "source": [
    "#Missing count and percentage of each column in the training set\n",
    "\n",
    "#Check for null and provide a count of the total\n",
    "missing_train = applicationtrainDF.isnull().sum()\n",
    "\n",
    "#Filter for any columns that have greater than 0 null values\n",
    "missing_train = missing_train[missing_train > 0]\n",
    "\n",
    "#Sort the columns in descending order based on count\n",
    "missing_train = missing_train.sort_values(ascending=False)\n",
    "\n",
    "#Provide a percentage of missing values in each column \n",
    "percent_missing_train = (missing_train / len(applicationtrainDF)) * 100\n",
    "percent_missing_train = percent_missing_train.round(2)\n",
    "\n",
    "#Create a data frame that includes the missing count and percentages\n",
    "missing_data_train = pd.DataFrame({'Missing Count': missing_train, 'Percentage': percent_missing_train})\n",
    "\n",
    "# Display all the columns based on the above criteria\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(missing_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf83ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Missing Count  Percentage\n",
      "COMMONAREA_MODE                       33495       68.72\n",
      "COMMONAREA_MEDI                       33495       68.72\n",
      "COMMONAREA_AVG                        33495       68.72\n",
      "NONLIVINGAPARTMENTS_MEDI              33347       68.41\n",
      "NONLIVINGAPARTMENTS_AVG               33347       68.41\n",
      "NONLIVINGAPARTMENTS_MODE              33347       68.41\n",
      "FONDKAPREMONT_MODE                    32797       67.28\n",
      "LIVINGAPARTMENTS_MODE                 32780       67.25\n",
      "LIVINGAPARTMENTS_MEDI                 32780       67.25\n",
      "LIVINGAPARTMENTS_AVG                  32780       67.25\n",
      "FLOORSMIN_MEDI                        32466       66.61\n",
      "FLOORSMIN_MODE                        32466       66.61\n",
      "FLOORSMIN_AVG                         32466       66.61\n",
      "OWN_CAR_AGE                           32312       66.29\n",
      "YEARS_BUILD_AVG                       31818       65.28\n",
      "YEARS_BUILD_MEDI                      31818       65.28\n",
      "YEARS_BUILD_MODE                      31818       65.28\n",
      "LANDAREA_MODE                         28254       57.96\n",
      "LANDAREA_AVG                          28254       57.96\n",
      "LANDAREA_MEDI                         28254       57.96\n",
      "BASEMENTAREA_MEDI                     27641       56.71\n",
      "BASEMENTAREA_AVG                      27641       56.71\n",
      "BASEMENTAREA_MODE                     27641       56.71\n",
      "NONLIVINGAREA_MEDI                    26084       53.51\n",
      "NONLIVINGAREA_MODE                    26084       53.51\n",
      "NONLIVINGAREA_AVG                     26084       53.51\n",
      "ELEVATORS_MEDI                        25189       51.68\n",
      "ELEVATORS_MODE                        25189       51.68\n",
      "ELEVATORS_AVG                         25189       51.68\n",
      "WALLSMATERIAL_MODE                    23893       49.02\n",
      "APARTMENTS_MODE                       23887       49.01\n",
      "APARTMENTS_MEDI                       23887       49.01\n",
      "APARTMENTS_AVG                        23887       49.01\n",
      "HOUSETYPE_MODE                        23619       48.46\n",
      "ENTRANCES_MODE                        23579       48.37\n",
      "ENTRANCES_MEDI                        23579       48.37\n",
      "ENTRANCES_AVG                         23579       48.37\n",
      "LIVINGAREA_AVG                        23552       48.32\n",
      "LIVINGAREA_MEDI                       23552       48.32\n",
      "LIVINGAREA_MODE                       23552       48.32\n",
      "FLOORSMAX_MEDI                        23321       47.84\n",
      "FLOORSMAX_MODE                        23321       47.84\n",
      "FLOORSMAX_AVG                         23321       47.84\n",
      "YEARS_BEGINEXPLUATATION_MEDI          22856       46.89\n",
      "YEARS_BEGINEXPLUATATION_MODE          22856       46.89\n",
      "YEARS_BEGINEXPLUATATION_AVG           22856       46.89\n",
      "TOTALAREA_MODE                        22624       46.41\n",
      "EMERGENCYSTATE_MODE                   22209       45.56\n",
      "EXT_SOURCE_1                          20532       42.12\n",
      "OCCUPATION_TYPE                       15605       32.01\n",
      "EXT_SOURCE_3                           8668       17.78\n",
      "AMT_REQ_CREDIT_BUREAU_MON              6049       12.41\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR             6049       12.41\n",
      "AMT_REQ_CREDIT_BUREAU_QRT              6049       12.41\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK             6049       12.41\n",
      "AMT_REQ_CREDIT_BUREAU_DAY              6049       12.41\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR             6049       12.41\n",
      "NAME_TYPE_SUITE                         911        1.87\n",
      "DEF_60_CNT_SOCIAL_CIRCLE                 29        0.06\n",
      "OBS_60_CNT_SOCIAL_CIRCLE                 29        0.06\n",
      "DEF_30_CNT_SOCIAL_CIRCLE                 29        0.06\n",
      "OBS_30_CNT_SOCIAL_CIRCLE                 29        0.06\n",
      "AMT_ANNUITY                              24        0.05\n",
      "EXT_SOURCE_2                              8        0.02\n"
     ]
    }
   ],
   "source": [
    "# See how many columns in applicationtestDF have null values\n",
    "\n",
    "# Check for null and provide a count of the total\n",
    "missing_test = applicationtestDF.isnull().sum()\n",
    "\n",
    "# Filter for any columns that have greater than 0 null values\n",
    "missing_test = missing_test[missing_test > 0]\n",
    "\n",
    "# Sort the columns in descending order based on count\n",
    "missing_test = missing_test.sort_values(ascending=False)\n",
    "\n",
    "# Provide a percentage of missing values in each \n",
    "percent_missing_test = (missing_test / len(applicationtestDF)) * 100\n",
    "percent_missing_test = percent_missing_test.round(2)\n",
    "\n",
    "# Create a data frame that includes the missing count and percentages\n",
    "missing_data_test = pd.DataFrame({'Missing Count': missing_test, 'Percentage': percent_missing_test})\n",
    "\n",
    "# Display all the columns based on the above criteria\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    print(missing_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2bc8a",
   "metadata": {},
   "source": [
    "The variables that are missing more than 40% of their values have been normalized. Their values range from 0-1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89436f75",
   "metadata": {},
   "source": [
    "#### Filtering missing values and printing summary metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ec2f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       COMMONAREA_MEDI  COMMONAREA_AVG  COMMONAREA_MODE  \\\n",
      "count         92646.00        92646.00         92646.00   \n",
      "mean              0.04            0.04             0.04   \n",
      "std               0.08            0.08             0.07   \n",
      "min               0.00            0.00             0.00   \n",
      "25%               0.01            0.01             0.01   \n",
      "50%               0.02            0.02             0.02   \n",
      "75%               0.05            0.05             0.05   \n",
      "max               1.00            1.00             1.00   \n",
      "\n",
      "       NONLIVINGAPARTMENTS_MEDI  NONLIVINGAPARTMENTS_MODE  \\\n",
      "count                  93997.00                  93997.00   \n",
      "mean                       0.01                      0.01   \n",
      "std                        0.05                      0.05   \n",
      "min                        0.00                      0.00   \n",
      "25%                        0.00                      0.00   \n",
      "50%                        0.00                      0.00   \n",
      "75%                        0.00                      0.00   \n",
      "max                        1.00                      1.00   \n",
      "\n",
      "       NONLIVINGAPARTMENTS_AVG  LIVINGAPARTMENTS_MODE  LIVINGAPARTMENTS_MEDI  \\\n",
      "count                 93997.00               97312.00               97312.00   \n",
      "mean                      0.01                   0.11                   0.10   \n",
      "std                       0.05                   0.10                   0.09   \n",
      "min                       0.00                   0.00                   0.00   \n",
      "25%                       0.00                   0.05                   0.05   \n",
      "50%                       0.00                   0.08                   0.08   \n",
      "75%                       0.00                   0.13                   0.12   \n",
      "max                       1.00                   1.00                   1.00   \n",
      "\n",
      "       LIVINGAPARTMENTS_AVG  FLOORSMIN_MODE  ...  LIVINGAREA_MEDI  \\\n",
      "count              97312.00        98869.00  ...        153161.00   \n",
      "mean                   0.10            0.23  ...             0.11   \n",
      "std                    0.09            0.16  ...             0.11   \n",
      "min                    0.00            0.00  ...             0.00   \n",
      "25%                    0.05            0.08  ...             0.05   \n",
      "50%                    0.08            0.21  ...             0.07   \n",
      "75%                    0.12            0.38  ...             0.13   \n",
      "max                    1.00            1.00  ...             1.00   \n",
      "\n",
      "       LIVINGAREA_MODE  LIVINGAREA_AVG  FLOORSMAX_MEDI  FLOORSMAX_AVG  \\\n",
      "count        153161.00       153161.00       154491.00      154491.00   \n",
      "mean              0.11            0.11            0.23           0.23   \n",
      "std               0.11            0.11            0.15           0.14   \n",
      "min               0.00            0.00            0.00           0.00   \n",
      "25%               0.04            0.05            0.17           0.17   \n",
      "50%               0.07            0.07            0.17           0.17   \n",
      "75%               0.13            0.13            0.33           0.33   \n",
      "max               1.00            1.00            1.00           1.00   \n",
      "\n",
      "       FLOORSMAX_MODE  YEARS_BEGINEXPLUATATION_AVG  \\\n",
      "count       154491.00                    157504.00   \n",
      "mean             0.22                         0.98   \n",
      "std              0.14                         0.06   \n",
      "min              0.00                         0.00   \n",
      "25%              0.17                         0.98   \n",
      "50%              0.17                         0.98   \n",
      "75%              0.33                         0.99   \n",
      "max              1.00                         1.00   \n",
      "\n",
      "       YEARS_BEGINEXPLUATATION_MEDI  YEARS_BEGINEXPLUATATION_MODE  \\\n",
      "count                     157504.00                     157504.00   \n",
      "mean                           0.98                          0.98   \n",
      "std                            0.06                          0.06   \n",
      "min                            0.00                          0.00   \n",
      "25%                            0.98                          0.98   \n",
      "50%                            0.98                          0.98   \n",
      "75%                            0.99                          0.99   \n",
      "max                            1.00                          1.00   \n",
      "\n",
      "       TOTALAREA_MODE  \n",
      "count       159080.00  \n",
      "mean             0.10  \n",
      "std              0.11  \n",
      "min              0.00  \n",
      "25%              0.04  \n",
      "50%              0.07  \n",
      "75%              0.13  \n",
      "max              1.00  \n",
      "\n",
      "[8 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Summary Metrics of the training set\n",
    "\n",
    "# Filter columns with over 40% null values\n",
    "missingdata_columns = missing_data_train[missing_data_train['Percentage'] > 40].index\n",
    "\n",
    "# Calculate summary metrics for filtered columns \n",
    "summary_metrics = applicationtrainDF[missingdata_columns].describe(include=np.number).round(2)\n",
    "\n",
    "# Display summary metrics\n",
    "print(summary_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cf7555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        COMMONAREA_MEDI  NONLIVINGAPARTMENTS_AVG\n",
      "0                0.0144                   0.0000\n",
      "1                0.0608                   0.0039\n",
      "13               0.0585                   0.0000\n",
      "14               0.1150                   0.0193\n",
      "18               0.0018                   0.0000\n",
      "...                 ...                      ...\n",
      "307495           0.0137                   0.0039\n",
      "307505           0.1441                   0.0154\n",
      "307506           0.0203                   0.0753\n",
      "307507           0.0022                   0.0000\n",
      "307508           0.0124                   0.0000\n",
      "\n",
      "[88507 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#View 2 of the columns' data from the summary metrics info above\n",
    "\n",
    "#Identify the two columns\n",
    "two_columns = [\"COMMONAREA_MEDI\", \"NONLIVINGAPARTMENTS_AVG\"]\n",
    "\n",
    "#create a dataframe of those columns where the rows do not contain null values\n",
    "two_columns_df = applicationtrainDF[applicationtrainDF[two_columns].notnull().all(axis=1)]\n",
    "\n",
    "#display the dataframe of the two columns\n",
    "print(two_columns_df[two_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c1356",
   "metadata": {},
   "source": [
    "As we progress in our model building process, we need to analyze the greater than 40% null value variables and how they interact with the model using a subsample of the training dataset. The sample should contain the rows of these variables that are not null to see if they are statiscally significant to the model. If they are stasticially significant, we can then choose to either impute the data or build our model off only the subsample of the dataset. If we were to use only 30% of the training dataset, we'd still have a sample size of around 92,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcfe160b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       EXT_SOURCE_3  AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
      "count     246546.00                   265992.00                  265992.00   \n",
      "mean           0.51                        0.03                       0.01   \n",
      "std            0.19                        0.20                       0.11   \n",
      "min            0.00                        0.00                       0.00   \n",
      "25%            0.37                        0.00                       0.00   \n",
      "50%            0.54                        0.00                       0.00   \n",
      "75%            0.67                        0.00                       0.00   \n",
      "max            0.90                        8.00                       9.00   \n",
      "\n",
      "       AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
      "count                  265992.00                  265992.00   \n",
      "mean                        0.27                       0.27   \n",
      "std                         0.92                       0.79   \n",
      "min                         0.00                       0.00   \n",
      "25%                         0.00                       0.00   \n",
      "50%                         0.00                       0.00   \n",
      "75%                         0.00                       0.00   \n",
      "max                        27.00                     261.00   \n",
      "\n",
      "       AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_YEAR  \\\n",
      "count                   265992.00                   265992.00   \n",
      "mean                         0.01                        1.90   \n",
      "std                          0.08                        1.87   \n",
      "min                          0.00                        0.00   \n",
      "25%                          0.00                        0.00   \n",
      "50%                          0.00                        1.00   \n",
      "75%                          0.00                        3.00   \n",
      "max                          4.00                       25.00   \n",
      "\n",
      "       DEF_30_CNT_SOCIAL_CIRCLE  OBS_60_CNT_SOCIAL_CIRCLE  \\\n",
      "count                 306490.00                 306490.00   \n",
      "mean                       0.14                      1.41   \n",
      "std                        0.45                      2.38   \n",
      "min                        0.00                      0.00   \n",
      "25%                        0.00                      0.00   \n",
      "50%                        0.00                      0.00   \n",
      "75%                        0.00                      2.00   \n",
      "max                       34.00                    344.00   \n",
      "\n",
      "       DEF_60_CNT_SOCIAL_CIRCLE  OBS_30_CNT_SOCIAL_CIRCLE  EXT_SOURCE_2  \\\n",
      "count                 306490.00                 306490.00     306851.00   \n",
      "mean                       0.10                      1.42          0.51   \n",
      "std                        0.36                      2.40          0.19   \n",
      "min                        0.00                      0.00          0.00   \n",
      "25%                        0.00                      0.00          0.39   \n",
      "50%                        0.00                      0.00          0.57   \n",
      "75%                        0.00                      2.00          0.66   \n",
      "max                       24.00                    348.00          0.85   \n",
      "\n",
      "       AMT_GOODS_PRICE  AMT_ANNUITY  CNT_FAM_MEMBERS  DAYS_LAST_PHONE_CHANGE  \n",
      "count        307233.00    307499.00        307509.00               307510.00  \n",
      "mean         538396.21     27108.57             2.15                 -962.86  \n",
      "std          369446.46     14493.74             0.91                  826.81  \n",
      "min           40500.00      1615.50             1.00                -4292.00  \n",
      "25%          238500.00     16524.00             2.00                -1570.00  \n",
      "50%          450000.00     24903.00             2.00                 -757.00  \n",
      "75%          679500.00     34596.00             3.00                 -274.00  \n",
      "max         4050000.00    258025.50            20.00                    0.00  \n"
     ]
    }
   ],
   "source": [
    "# Summary Metrics of the training set\n",
    "\n",
    "# Filter columns with UNDER 40% null values\n",
    "missingdata_columns2 = missing_data_train[missing_data_train['Percentage'] < 40].index\n",
    "\n",
    "# Calculate summary metrics for filtered columns\n",
    "summary_metrics2 = applicationtrainDF[missingdata_columns2].describe(include=np.number).round(2)\n",
    "\n",
    "# Display summary metrics\n",
    "print(summary_metrics2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a5906",
   "metadata": {},
   "source": [
    "When examining the variables that contain less than 40% null values, we can see that we need to take care of some possible outliers in the data. The max values listed on the summary stastics for some of the variables is well above 2 standard deviations from the mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb8b3c",
   "metadata": {},
   "source": [
    "#### Participation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9e3ed",
   "metadata": {},
   "source": [
    "\n",
    "#### Rachel Butterfield\n",
    "\n",
    "Rachel Butterfield explored the scope of missing data in the training and test datasets. She examined all the variables in both sets by looking at the total count and percentage of missing values, examining a handful of the variables to see what the values were, identified possible outliers in the data. She also provided some strategic suggestions as to how to manage the missing data as we continue building out model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "138.99px",
    "width": "481.99px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "573.297px",
    "left": "86px",
    "top": "159px",
    "width": "254px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
